{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value # only leaf nodes have value\n",
    "class DecisionTree():\n",
    "    def __init__(self):\n",
    "        self.root=None\n",
    "    def _entropy(self,y):\n",
    "        classes,count=np.unique(y,return_counts=True)\n",
    "        prob=count/len(y)\n",
    "        return -np.sum(prob*np.log2(prob+1e-9)) #avoids taking log(0), which causes errors.\n",
    "    def _split(self ,X,y,feature_index,threshold):\n",
    "        leftmask=X[:,feature_index]<=threshold\n",
    "        rightmask=~leftmask\n",
    "        return X[leftmask],y[leftmask],X[rightmask],y[rightmask]\n",
    "    def best_split(self,X,y):\n",
    "        best_gain=-1\n",
    "        best_feature=None\n",
    "        best_threshold=None\n",
    "        parententropy=self._entropy(y)\n",
    "        n_features=X.shape[1]\n",
    "        for feature_index in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                X_left, y_left, X_right, y_right = self._split(X, y, feature_index, threshold)\n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "                left_entropy = self._entropy(y_left)\n",
    "                right_entropy = self._entropy(y_right)\n",
    "                weighted_entropy = (len(y_left) / len(y)) * left_entropy + (len(y_right) / len(y)) * right_entropy\n",
    "                info_gain = parententropy - weighted_entropy\n",
    "                if info_gain > best_gain:\n",
    "                    best_gain = info_gain\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold\n",
    "    def _build_tree(self,X,y,depth=0,max_depth=3):\n",
    "        # If all labels are the same or max depth is reached, return a leaf node\n",
    "        if len(set(y)) == 1 or depth >= max_depth:\n",
    "            leaf_value = max(set(y), key=list(y).count)\n",
    "            return Node(value=leaf_value)\n",
    "        feature, threshold = self.best_split(X, y)\n",
    "        if feature is None:  #if we dont get nice info gain it is better to stop spliting their so return the node\n",
    "            leaf_value = max(set(y), key=list(y).count)\n",
    "            return Node(value=leaf_value)\n",
    "        X_left, y_left, X_right, y_right = self._split(X, y, feature, threshold)\n",
    "        left_child = self._build_tree(X_left, y_left, depth + 1, max_depth)\n",
    "        right_child = self._build_tree(X_right, y_right, depth + 1, max_depth)\n",
    "\n",
    "        return Node(feature, threshold, left_child, right_child)\n",
    "    def predict_sample(self,node, sample):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if sample[node.feature] <= node.threshold:\n",
    "            return self.predict_sample(node.left, sample)\n",
    "        else:\n",
    "            return self.predict_sample(node.right, sample)\n",
    "    def predict(self, X):\n",
    "        return [self.predict_sample(self.root, sample) for sample in X]\n",
    "    def fit(self, X, y, max_depth=3):\n",
    "        self.root = self._build_tree(X, y, 0, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d89b1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1], [2, 1], [3, 2], [6, 5], [7, 8], [8, 9]])\n",
    "y = np.array([0, 0, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62080209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1)]\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTree()\n",
    "tree.fit(X, y, max_depth=3)\n",
    "\n",
    "print(\"Predictions:\", tree.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d14522df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: [Age, Salary]\n",
    "X = np.array([\n",
    "    [22, 25],\n",
    "    [25, 30],\n",
    "    [47, 60],\n",
    "    [52, 80],\n",
    "    [46, 50],\n",
    "    [56, 90],\n",
    "    [28, 40],\n",
    "    [30, 60]\n",
    "])\n",
    "\n",
    "# Target: 0 = No, 1 = Yes\n",
    "y = np.array([0, 0, 1, 1, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10313353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0)]\n",
      "Actual:      [0, 0, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTree()\n",
    "tree.fit(X, y, max_depth=3)\n",
    "\n",
    "predictions = tree.predict(X)\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Actual:     \", y.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b14a5d0",
   "metadata": {},
   "source": [
    "In classic decision tree algorithms (like ID3, C4.5, or CART):\n",
    "\n",
    "- Each split is made independently.\n",
    "\n",
    "- At every node, we search all features and all thresholds again.\n",
    "\n",
    "- If the same feature is still the best choice, we use it again.\n",
    "\n",
    "if you want to prevent using the same feature again (e.g., for some educational or constrained reason), you'd need to:\n",
    "\n",
    "- Track used features, and\n",
    "\n",
    "- Remove them from the candidate list in best_split().\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf734122",
   "metadata": {},
   "source": [
    "RANDOM FOREST\n",
    "- Train multiple decision trees on different random subsets of the data (bootstrapping).\n",
    "\n",
    "- Optionally select a random subset of features at each split (feature bagging).\n",
    "\n",
    "- Aggregate predictions using majority voting (for classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e598625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=5, max_depth=3, sample_size=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.sample_size = sample_size  # Size of data for bootstrapping\n",
    "        self.trees = []\n",
    "\n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        n_samples = self.sample_size or len(X)\n",
    "        indices = np.random.choice(len(X), size=n_samples, replace=True)\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            tree = DecisionTree()\n",
    "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
    "            tree.fit(X_sample, y_sample, max_depth=self.max_depth)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def _vote(self, predictions):\n",
    "        count = Counter(predictions)\n",
    "        return count.most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Collect predictions from all trees\n",
    "        all_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        # Transpose so each row is a sample's predictions from all trees\n",
    "        all_preds = all_preds.T\n",
    "        # Majority vote for each sample\n",
    "        final_preds = [self._vote(row) for row in all_preds]\n",
    "        return final_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a81690a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Predictions: [np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0)]\n"
     ]
    }
   ],
   "source": [
    "# Your previous dataset\n",
    "X = np.array([\n",
    "    [22, 25],\n",
    "    [25, 30],\n",
    "    [47, 60],\n",
    "    [52, 80],\n",
    "    [46, 50],\n",
    "    [56, 90],\n",
    "    [28, 40],\n",
    "    [30, 60]\n",
    "])\n",
    "y = np.array([0, 0, 1, 1, 1, 1, 0, 0])\n",
    "\n",
    "# Train the ensemble\n",
    "forest = RandomForest(n_trees=5, max_depth=3)\n",
    "forest.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "predictions = forest.predict(X)\n",
    "print(\"Ensemble Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d5aa9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fc07fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Reusing your DecisionTree with regression support\n",
    "class TreeRegressor:\n",
    "    def __init__(self, max_depth=3):\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "\n",
    "    def _mse(self, y):\n",
    "        mean = np.mean(y)\n",
    "        return np.mean((y - mean)**2)\n",
    "\n",
    "    def _split(self, X, y, feature_index, threshold):\n",
    "        left = X[:, feature_index] <= threshold\n",
    "        return X[left], y[left], X[~left], y[~left]\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_mse = float('inf')\n",
    "        best_feat, best_thr = None, None\n",
    "        for f in range(X.shape[1]):\n",
    "            for thr in np.unique(X[:, f]):\n",
    "                Xl, yl, Xr, yr = self._split(X, y, f, thr)\n",
    "                if len(yl)==0 or len(yr)==0: continue\n",
    "                mse = (len(yl)*self._mse(yl) + len(yr)*self._mse(yr)) / len(y)\n",
    "                if mse < best_mse:\n",
    "                    best_mse, best_feat, best_thr = mse, f, thr\n",
    "        return best_feat, best_thr\n",
    "\n",
    "    def _build(self, X, y, depth=0):\n",
    "        if depth==self.max_depth or len(set(y))==1:\n",
    "            return {'leaf': np.mean(y)}\n",
    "        feat, thr = self._best_split(X, y)\n",
    "        if feat is None:\n",
    "            return {'leaf': np.mean(y)}\n",
    "        Xl, yl, Xr, yr = self._split(X, y, feat, thr)\n",
    "        return {\n",
    "            'feat': feat,\n",
    "            'thr': thr,\n",
    "            'left': self._build(Xl, yl, depth+1),\n",
    "            'right': self._build(Xr, yr, depth+1),\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build(X, y)\n",
    "\n",
    "    def _predict_one(self, node, x):\n",
    "        if 'leaf' in node:\n",
    "            return node['leaf']\n",
    "        if x[node['feat']] <= node['thr']:\n",
    "            return self._predict_one(node['left'], x)\n",
    "        else:\n",
    "            return self._predict_one(node['right'], x)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(self.root, x) for x in X])\n",
    "\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=5, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        self.init_val = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Start with mean prediction\n",
    "        self.init_val = np.mean(y)\n",
    "        pred = np.full_like(y, self.init_val, dtype=float)\n",
    "\n",
    "        for m in range(self.n_estimators):\n",
    "            \n",
    "            residual = y - pred\n",
    "            tree = TreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residual)\n",
    "            update = tree.predict(X)\n",
    "            pred += self.lr * update\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.full((len(X),), self.init_val, dtype=float)\n",
    "        for tree in self.trees:\n",
    "            pred += self.lr * tree.predict(X)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c764cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [6, 3],\n",
    "    [8, 4],\n",
    "    [5, 2],\n",
    "    [7, 5],\n",
    "    [6, 1]\n",
    "])\n",
    "\n",
    "y = np.array([4, 6, 3, 7, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef21d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.06003785 5.75984858 3.21013249 6.60975395 2.36022712]\n",
      "[4, 5, 3, 6, 2]\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=18, learning_rate=0.1, max_depth=3)\n",
    "model.fit(X, y)\n",
    "\n",
    "predictions = model.predict(X)\n",
    "print(predictions)\n",
    "rounded_preds = [int(round(p, 2)) for p in predictions]\n",
    "print(rounded_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a1d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3864f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
